{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = data.resting_blood_pressure.quantile(0.25)\n",
    "q2 = data.resting_blood_pressure.quantile(0.75)\n",
    "print(q1,q2)\n",
    "IQR = q2-q1\n",
    "print(IQR)\n",
    "lower_limit = q1-1.5*IQR\n",
    "upper_limit = q2+1.5*IQR\n",
    "print(lower_limit,upper_limit)\n",
    "\n",
    "q3 = data.cholesterol.quantile(0.25)\n",
    "q4 = data.cholesterol.quantile(0.75)\n",
    "print(q3,q4)\n",
    "IQR = q4-q3\n",
    "print(IQR)\n",
    "lower_limit1 = q3-1.5*IQR\n",
    "upper_limit1= q4+1.5*IQR\n",
    "print(lower_limit1,upper_limit1)\n",
    "\n",
    "q5 = data.max_heart_rate_achieved.quantile(0.25)\n",
    "q6 = data.max_heart_rate_achieved.quantile(0.75)\n",
    "print(q5,q6)\n",
    "IQR = q6-q5\n",
    "print(IQR)\n",
    "lower_limit2 = q5-1.5*IQR\n",
    "upper_limit2 = q6+1.5*IQR\n",
    "print(lower_limit2,upper_limit2)\n",
    "\n",
    "df_no_outlier =data[(data.resting_blood_pressure>lower_limit)&(data.resting_blood_pressure<upper_limit)&(data.cholesterol>lower_limit1)&(data.cholesterol<upper_limit1)&(data.max_heart_rate_achieved>lower_limit2)&(data.max_heart_rate_achieved<upper_limit2)]\n",
    "#df_no_outlier = data[(data.max_heart_rate_achieved>lower_limit2)&(data.max_heart_rate_achieved<upper_limit2)]\n",
    "X = df_no_outlier.drop('target',axis=1)\n",
    "y = df_no_outlier['target']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF train roc-auc: 0.9999999999999999\n",
      "RF test roc-auc: 0.8604878048780488\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "ytrain_pred = rf_model.predict_proba(X_train)\n",
    "print('RF train roc-auc: {}'.format(roc_auc_score(y_train, ytrain_pred[:,1])))\n",
    "ytest_pred = rf_model.predict_proba(X_test)\n",
    "print('RF test roc-auc: {}'.format(roc_auc_score(y_test, ytest_pred[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic train roc-auc: 0.9367099955177052\n",
      "Logistic test roc-auc: 0.8707317073170732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nisarga/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_classifier=LogisticRegression()\n",
    "log_classifier.fit(X_train, y_train)\n",
    "ytrain_pred = log_classifier.predict_proba(X_train)\n",
    "print('Logistic train roc-auc: {}'.format(roc_auc_score(y_train, ytrain_pred[:,1])))\n",
    "ytest_pred = log_classifier.predict_proba(X_test)\n",
    "print('Logistic test roc-auc: {}'.format(roc_auc_score(y_test, ytest_pred[:,1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost train roc-auc: 0.9919318691169878\n",
      "Adaboost test roc-auc: 0.813170731707317\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada_classifier=AdaBoostClassifier()\n",
    "ada_classifier.fit(X_train, y_train)\n",
    "ytrain_pred = ada_classifier.predict_proba(X_train)\n",
    "print('Adaboost train roc-auc: {}'.format(roc_auc_score(y_train, ytrain_pred[:,1])))\n",
    "ytest_pred = ada_classifier.predict_proba(X_test)\n",
    "print('Adaboost test roc-auc: {}'.format(roc_auc_score(y_test, ytest_pred[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost train roc-auc: 0.8685791125056028\n",
      "Adaboost test roc-auc: 0.6178048780487805\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_classifier=KNeighborsClassifier()\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "ytrain_pred = knn_classifier.predict_proba(X_train)\n",
    "print('Adaboost train roc-auc: {}'.format(roc_auc_score(y_train, ytrain_pred[:,1])))\n",
    "ytest_pred = knn_classifier.predict_proba(X_test)\n",
    "print('Adaboost test roc-auc: {}'.format(roc_auc_score(y_test, ytest_pred[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:08:22] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "xgboost train roc-auc: 1.0\n",
      "xgboost test roc-auc: 0.6178048780487805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nisarga/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "ytrain_pred = model.predict_proba(X_train)\n",
    "print('xgboost train roc-auc: {}'.format(roc_auc_score(y_train, ytrain_pred[:,1])))\n",
    "ytest_pred = knn_classifier.predict_proba(X_test)\n",
    "print('xgboost test roc-auc: {}'.format(roc_auc_score(y_test, ytest_pred[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble test roc-auc: 0.8351219512195122\n"
     ]
    }
   ],
   "source": [
    "pred=[]\n",
    "for model in [rf_model,log_classifier,ada_classifier,knn_classifier,model]:\n",
    "    pred.append(pd.Series(model.predict_proba(X_test)[:,1]))\n",
    "final_prediction=pd.concat(pred,axis=1).mean(axis=1)\n",
    "print('Ensemble test roc-auc: {}'.format(roc_auc_score(y_test,final_prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.001704</td>\n",
       "      <td>0.492998</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.007949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.775028</td>\n",
       "      <td>0.524752</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.994028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.082235</td>\n",
       "      <td>0.471629</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.002566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.005923</td>\n",
       "      <td>0.455544</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.020976</td>\n",
       "      <td>0.459738</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.041957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.742137</td>\n",
       "      <td>0.535638</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.513799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.779362</td>\n",
       "      <td>0.546476</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.940602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.949413</td>\n",
       "      <td>0.537390</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.010784</td>\n",
       "      <td>0.463222</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.010045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.068093</td>\n",
       "      <td>0.467233</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.715520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2    3         4\n",
       "0   0.16  0.001704  0.492998  0.2  0.007949\n",
       "1   0.83  0.775028  0.524752  0.6  0.994028\n",
       "2   0.10  0.082235  0.471629  0.8  0.002566\n",
       "3   0.00  0.005923  0.455544  0.6  0.000321\n",
       "4   0.11  0.020976  0.459738  0.2  0.041957\n",
       "..   ...       ...       ...  ...       ...\n",
       "86  0.54  0.742137  0.535638  0.4  0.513799\n",
       "87  0.69  0.779362  0.546476  0.4  0.940602\n",
       "88  0.99  0.949413  0.537390  1.0  0.999267\n",
       "89  0.18  0.010784  0.463222  0.6  0.010045\n",
       "90  0.51  0.068093  0.467233  0.4  0.715520\n",
       "\n",
       "[91 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat(pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.172530\n",
       "1     0.744762\n",
       "2     0.291286\n",
       "3     0.212357\n",
       "4     0.166534\n",
       "        ...   \n",
       "86    0.546315\n",
       "87    0.671288\n",
       "88    0.895214\n",
       "89    0.252810\n",
       "90    0.432169\n",
       "Length: 91, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-78fe86c9ea22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_prediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \u001b[0mmodified\u001b[0m \u001b[0;32mwith\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m     \"\"\"\n\u001b[0;32m-> 1071\u001b[0;31m     return fbeta_score(y_true, y_pred, beta=1, labels=labels,\n\u001b[0m\u001b[1;32m   1072\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m                        \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \"\"\"\n\u001b[1;32m   1194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m     _, _, f, _ = precision_recall_fscore_support(y_true, y_pred,\n\u001b[0m\u001b[1;32m   1196\u001b[0m                                                  \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m                                                  \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1462\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1463\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1464\u001b[0;31m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0m\u001b[1;32m   1465\u001b[0m                                     pos_label)\n\u001b[1;32m   1466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1275\u001b[0m                          str(average_options))\n\u001b[1;32m   1276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1277\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1278\u001b[0m     \u001b[0;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m     \u001b[0;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0m\u001b[1;32m     93\u001b[0m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15809703, 0.1629714 , 0.16612113, 0.16653407, 0.17253014,\n",
       "       0.19287786, 0.2079738 , 0.21235744, 0.21291202, 0.21800956,\n",
       "       0.22370449, 0.24304795, 0.2479613 , 0.25281015, 0.26034877,\n",
       "       0.2732856 , 0.28840995, 0.29128607, 0.29158431, 0.31085873,\n",
       "       0.31132286, 0.32978364, 0.35983302, 0.37252427, 0.38693095,\n",
       "       0.4308866 , 0.43216922, 0.45095828, 0.48948433, 0.49673857,\n",
       "       0.49784137, 0.50480405, 0.51754537, 0.54631462, 0.55028684,\n",
       "       0.55546766, 0.55835729, 0.56037246, 0.57610124, 0.58272534,\n",
       "       0.58786255, 0.62186686, 0.62649811, 0.63157113, 0.67128787,\n",
       "       0.6803837 , 0.68136207, 0.68731844, 0.68761233, 0.69473442,\n",
       "       0.69971808, 0.71503265, 0.72620441, 0.73006656, 0.73236124,\n",
       "       0.74447016, 0.74476166, 0.74520412, 0.75353907, 0.76604343,\n",
       "       0.77098523, 0.773745  , 0.78490759, 0.78525795, 0.78532488,\n",
       "       0.7894049 , 0.79134667, 0.80580072, 0.81316482, 0.81656299,\n",
       "       0.83269537, 0.83557093, 0.83838212, 0.84230561, 0.84471334,\n",
       "       0.84526585, 0.84586131, 0.85282973, 0.85374139, 0.85544447,\n",
       "       0.87880748, 0.8952141 , 0.90108563])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Calculate the ROc Curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "#fpr, tpr, thresholds = roc_curve(y_test, final_prediction)\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, final_prediction)\n",
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.291584, F-Score=0.835\n"
     ]
    }
   ],
   "source": [
    "fscore = (2 * precision * recall) / (precision + recall)\n",
    "# locate the index of the largest f score\n",
    "ix = argmax(fscore)\n",
    "print('Best Threshold=%f, F-Score=%.3f' % (thresholds[ix], fscore[ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.14142136 0.52915026 0.51608281 0.55171573 0.54459652\n",
      " 0.5934603  0.58559955 0.61564957 0.60727299 0.68858285 0.66918225\n",
      " 0.72851335 0.71771997 0.72884807 0.71771997 0.74963406 0.73782806\n",
      " 0.74800548 0.73584198 0.75546787 0.74277003 0.76157731 0.74833148\n",
      " 0.76636615 0.75255662 0.76125698 0.74702663 0.76381584 0.73385052\n",
      " 0.74963406 0.63091107 0.63744918 0.43728653 0.4417261  0.        ]\n",
      "Best Threshold=0.450958, G-Mean=0.766\n",
      "Best Threshold=0.359833\n"
     ]
    }
   ],
   "source": [
    "from numpy import sqrt\n",
    "from numpy import argmax\n",
    "gmeans = sqrt(tpr * (1-fpr))\n",
    "print(gmeans)\n",
    "ix = argmax(gmeans)\n",
    "print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n",
    "J = tpr - fpr\n",
    "ix = argmax(J)\n",
    "best_thresh = thresholds[ix]\n",
    "print('Best Threshold=%f' % (best_thresh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thresholds</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.291584</td>\n",
       "      <td>0.78022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.311323</td>\n",
       "      <td>0.78022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.359833</td>\n",
       "      <td>0.78022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.386931</td>\n",
       "      <td>0.78022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.432169</td>\n",
       "      <td>0.78022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    thresholds  accuracy\n",
       "30    0.291584   0.78022\n",
       "29    0.311323   0.78022\n",
       "28    0.359833   0.78022\n",
       "27    0.386931   0.78022\n",
       "25    0.432169   0.78022"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_ls = []\n",
    "for thres in thresholds:\n",
    "    y_pred = np.where(final_prediction>thres,1,0)\n",
    "    accuracy_ls.append(accuracy_score(y_test, y_pred, normalize=True))\n",
    "    \n",
    "accuracy_ls = pd.concat([pd.Series(thresholds), pd.Series(accuracy_ls)],\n",
    "                        axis=1)\n",
    "accuracy_ls.columns = ['thresholds', 'accuracy']\n",
    "accuracy_ls.sort_values(by='accuracy', ascending=False, inplace=True)\n",
    "accuracy_ls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thresholds</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.291584</td>\n",
       "      <td>0.780220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.311323</td>\n",
       "      <td>0.780220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.359833</td>\n",
       "      <td>0.780220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.386931</td>\n",
       "      <td>0.780220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.432169</td>\n",
       "      <td>0.780220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.430887</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.450958</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.496739</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.497841</td>\n",
       "      <td>0.758242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.517545</td>\n",
       "      <td>0.758242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.560372</td>\n",
       "      <td>0.747253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.546315</td>\n",
       "      <td>0.747253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.555468</td>\n",
       "      <td>0.747253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.558357</td>\n",
       "      <td>0.736264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.576101</td>\n",
       "      <td>0.736264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.621867</td>\n",
       "      <td>0.725275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.631571</td>\n",
       "      <td>0.725275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.243048</td>\n",
       "      <td>0.725275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.671288</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.223704</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.626498</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.694734</td>\n",
       "      <td>0.681319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.715033</td>\n",
       "      <td>0.681319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.745204</td>\n",
       "      <td>0.637363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.162971</td>\n",
       "      <td>0.637363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.158097</td>\n",
       "      <td>0.626374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.770985</td>\n",
       "      <td>0.626374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.753539</td>\n",
       "      <td>0.626374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.773745</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.785325</td>\n",
       "      <td>0.604396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.789405</td>\n",
       "      <td>0.593407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.805801</td>\n",
       "      <td>0.593407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.816563</td>\n",
       "      <td>0.593407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.099461</td>\n",
       "      <td>0.560440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.901086</td>\n",
       "      <td>0.450549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.901086</td>\n",
       "      <td>0.450549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    thresholds  accuracy\n",
       "30    0.291584  0.780220\n",
       "29    0.311323  0.780220\n",
       "28    0.359833  0.780220\n",
       "27    0.386931  0.780220\n",
       "25    0.432169  0.780220\n",
       "26    0.430887  0.769231\n",
       "24    0.450958  0.769231\n",
       "23    0.496739  0.769231\n",
       "22    0.497841  0.758242\n",
       "21    0.517545  0.758242\n",
       "17    0.560372  0.747253\n",
       "20    0.546315  0.747253\n",
       "19    0.555468  0.747253\n",
       "18    0.558357  0.736264\n",
       "16    0.576101  0.736264\n",
       "15    0.621867  0.725275\n",
       "13    0.631571  0.725275\n",
       "31    0.243048  0.725275\n",
       "12    0.671288  0.714286\n",
       "32    0.223704  0.714286\n",
       "14    0.626498  0.714286\n",
       "11    0.694734  0.681319\n",
       "10    0.715033  0.681319\n",
       "9     0.745204  0.637363\n",
       "33    0.162971  0.637363\n",
       "34    0.158097  0.626374\n",
       "7     0.770985  0.626374\n",
       "8     0.753539  0.626374\n",
       "6     0.773745  0.615385\n",
       "5     0.785325  0.604396\n",
       "4     0.789405  0.593407\n",
       "3     0.805801  0.593407\n",
       "2     0.816563  0.593407\n",
       "35    0.099461  0.560440\n",
       "1     0.901086  0.450549\n",
       "0     1.901086  0.450549"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr):\n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_curve(fpr,tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-4142fa246301>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted_proba\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytest_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy: %.2f%%\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0m\u001b[1;32m     93\u001b[0m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "threshold = 0.291584\n",
    "\n",
    "predicted_proba = rf_model.predict_proba(X_test)\n",
    "predicted = (predicted_proba [:,1] >= threshold).astype('int')\n",
    "\n",
    "accuracy = accuracy_score(y_test,ytest_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
